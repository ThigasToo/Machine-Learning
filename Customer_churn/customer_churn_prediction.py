# -*- coding: utf-8 -*-
"""Customer Churn Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AhMHUDIiyvxp_u5eLW8cACdqbibRvXLH

Importing the dependencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBRFClassifier

"""Data loading and understanding"""

# load the csv data
df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')
df.head()

df.shape

pd.set_option('display.max_columns', None)
df.head()

df.info()

# transform the Total Charges
#df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
#this transformation in this step does not work because of the empty spaces in 'Total Charges'

#dropping the customer ID column
df = df.drop(columns =['customerID'])

df.info()

df.columns

# printing the unique values in all the columns

for col in df.columns:
    print(f'{col}: {df[col].unique()}')
    print("-"*50)

print(df.isnull().sum())

df['TotalCharges'] = df['TotalCharges'].replace({" ": "0.0"})

print(df.isnull().sum())

df['TotalCharges'] = df["TotalCharges"].astype(float)

df.info()

# checking the class distribution of target column
print(df['Churn'].value_counts())

"""Insights:
- Removed the costumer ID
- No missing values
- Missing values in the Total Charges columns was replace with 0
- Class inbalance identified in the target

Exploratory Data analysis
"""

df.shape

df.columns

df.describe()

"""Numerical features analysis

"""

def plot_histogram(df, column_name):
  plt.figure(figsize=(5, 3))
  sns.histplot(df[column_name], kde=True)
  plt.title(f'Distribution of {column_name}')

  #calculate mean and median values for the columns
  col_mean = df[column_name].mean()
  col_median = df[column_name].median()

  # add vertical lines for mean and median
  plt.axvline(col_mean, color='red', linestyle="--", label="Mean")
  plt.axvline(col_median, color='green', linestyle="-", label="Median")

  plt.legend()

  plt.show()

plot_histogram(df, "tenure")

plot_histogram(df, "MonthlyCharges")

plot_histogram(df, "TotalCharges")

# boxplot for numerical features
def plot_boxplot(df, column_name):
  plt.figure(figsize=(5, 3))
  sns.boxplot(y=df[column_name])
  plt.title(f'Distribution of {column_name}')
  plt.ylabel(column_name)
  plt.show()

plot_boxplot(df, "tenure")

plot_boxplot(df, "MonthlyCharges")

plot_boxplot(df, "TotalCharges")

#correlation for numerical features
#heatmap
plt.figure(figsize=(8, 4))
sns.heatmap(df[["tenure", "MonthlyCharges", "TotalCharges"]].corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.show()

"""Categorical Features"""

object_cols = df.select_dtypes(include='object').columns.to_list()

object_cols = ["SeniorCitizen"] + object_cols

object_cols

#Countplot for categorical columns


for col in object_cols:
  plt.figure(figsize=(5, 3))
  sns.countplot(x=df[col])
  plt.title(f'Count Plot of {col}')
  plt.show()

"""Data Preprocessing"""

df.head(3)

#Label econding of target column

df["Churn"] = df["Churn"].replace({"Yes": 1, "No": 0})

df.head(3)

print(df["Churn"].value_counts())

#Label econding of categorical features

# identifying columns with object data type

object_columns = df.select_dtypes(include='object').columns

print(object_columns)

# initialize a dictionary to save encoders
encoders = {}

# apply label encoding and store encoders
for column in object_columns:
    label_encoder = LabelEncoder()
    df[column] = label_encoder.fit_transform(df[column])
    encoders[column] = label_encoder

# save the encoders to a pickle file
import pickle
with open('encoders.pkl', 'wb') as f:
    pickle.dump(encoders, f)

encoders

df.head()

"""Training and test data split"""

# spliting the features and target
X = df.drop(columns = ["Churn"])
y = df["Churn"]

print(X)

print(y)

# split training and test data
x_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(y_train.value_counts())

"""Synthetic Minority Oversampling Techinique (SMOTe)"""

smote = SMOTE(random_state=42)
x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)

print(y_train_smote.value_counts())

"""Model Training

training with default hyperparameters
"""

# dictionary of models
models = {
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "XGBoost": XGBRFClassifier(random_state=42)
}

# dictionary to store the cross validation results
cv_scores = {}

# perform 5-fold cross validation for each model
for model_name, model in models.items():
    print(f"Training {model_name} with default parameters")
    scores = cross_val_score(model, x_train_smote, y_train_smote, cv=5, scoring='accuracy')
    cv_scores[model_name] = scores
    print(f"{model_name} cross_validation accuracy: {np.mean(scores):.2f}")
    print("-"*70)

cv_scores

"""Random Forest gives the highest acurracy compered to others models"""

rfc = RandomForestClassifier(random_state=42)

rfc.fit(x_train_smote, y_train_smote)

print(y_test.value_counts())

"""Model Evaluation"""

# evaluate on test data (with inbalanced test data: more 0 than 1)
y_test_pred = rfc.predict(X_test)

print("Acurracy Score: \n", accuracy_score(y_test, y_test_pred))
print("Confusion Matrix: \n", confusion_matrix(y_test, y_test_pred))
print("Classification Report: \n", classification_report(y_test, y_test_pred))

X.columns.tolist()

#save the training model as a pickle file
model_data = {"model": rfc, "features_names" : X.columns.tolist()}

import pickle
with open('customer_churn_model.pkl', 'wb') as f:
    pickle.dump(model_data, f)

"""Load the saved model and build a Predictive system"""

# load the saved model and the features names
with open("customer_churn_model.pkl", "rb") as f:
    model_data = pickle.load(f)

loaded_model = model_data["model"]
loaded_features_names = model_data["features_names"]

print(loaded_model)

print(loaded_features_names)



imput_data = {'gender': 'Female',
    'SeniorCitizen': 0,
    'Partner': 'Yes',
    'Dependents': 'No',
    'tenure': 1,
    'PhoneService': 'No',
    'MultipleLines': 'No phone service',
    'InternetService': 'DSL',
    'OnlineSecurity': 'No',
    'OnlineBackup': 'Yes',
    'DeviceProtection': 'No',
    'TechSupport': 'No',
    'StreamingTV': 'No',
    'StreamingMovies': 'No',
    'Contract': 'Month-to-month',
    'PaperlessBilling': 'Yes',
    'PaymentMethod': 'Electronic check',
    'MonthlyCharges': 29.85,
    'TotalCharges': 29.85}

imput_data_df = pd.DataFrame([imput_data])

with open("encoders.pkl", "rb") as f:
    encoders = pickle.load(f)

# encode categorical features using saved encoders
for column, encoder in encoders.items():
    imput_data_df[column] = encoder.transform(imput_data_df[column])

# make predictions using the loaded model
prediction = loaded_model.predict(imput_data_df)
prediction_prob = loaded_model.predict_proba(imput_data_df)

print(prediction)

#results
print(f"Prediction: {"Churn" if prediction[0] == 1 else "No Churn"}")
print(f"Prediction Probability: {prediction_prob}")

imput_data = {
    'gender': 'Female',
    'SeniorCitizen': 1,
    'Partner': 'Yes',
    'Dependents': 'Yes',
    'tenure': 1,
    'PhoneService': 'Yes',
    'MultipleLines': 'No phone service',
    'InternetService': 'DSL',
    'OnlineSecurity': 'Yes',
    'OnlineBackup': 'Yes',
    'DeviceProtection': 'No',
    'TechSupport': 'No',
    'StreamingTV': 'Yes',
    'StreamingMovies': 'Yes',
    'Contract': 'Month-to-month',
    'PaperlessBilling': 'Yes',
    'PaymentMethod': 'Electronic check',
    'MonthlyCharges': 60,
    'TotalCharges': 60
}

imput_data_df = pd.DataFrame([imput_data])

with open("encoders.pkl", "rb") as f:
    encoders = pickle.load(f)

# encode categorical features using saved encoders
for column, encoder in encoders.items():
    if column in imput_data_df.columns:
        imput_data_df[column] = encoder.transform(imput_data_df[column])

# make predictions using the loaded model
prediction = loaded_model.predict(imput_data_df)
prediction_prob = loaded_model.predict_proba(imput_data_df)

print(prediction)

#results
print(f"Prediction: {"Churn" if prediction[0] == 1 else "No Churn"}")
print(f"Prediction Probability: {prediction_prob}")